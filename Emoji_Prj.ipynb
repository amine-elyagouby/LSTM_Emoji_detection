{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bgPpghocFIa"
      },
      "source": [
        "# Emoji Prediction Neural network\n",
        "Have you ever wanted to make your text messages more expressive? our emojifier app will help you do that.\n",
        "Rather than writing:\n",
        ">\"Congratulations on the promotion! Let's get coffee and talk. Love you!\"   \n",
        "\n",
        "The emojifier can automatically turn this into:\n",
        ">\"Congratulations on the promotion! üëç  Let's get coffee and talk. ‚òïÔ∏è Love you! ‚ù§Ô∏è\"\n",
        "\n",
        "You'll implement a model which inputs a sentence (such as \"Let's go see the baseball game tonight!\") and finds the most appropriate emoji to be used with this sentence (‚öæÔ∏è).\n",
        "\n",
        "### Using Word Vectors to Improve Emoji Lookups\n",
        "* In many emoji interfaces, you need to remember that ‚ù§Ô∏è  is the \"heart\" symbol rather than the \"love\" symbol.\n",
        "    * In other words, you'll have to remember to type \"heart\" to find the desired emoji, and typing \"love\" won't bring up that symbol.\n",
        "* You can make a more flexible emoji interface by using word vectors!\n",
        "* When using word vectors, you'll see that even if your training set explicitly relates only a few words to a particular emoji, your algorithm will be able to generalize and associate additional words in the test set to the same emoji.\n",
        "    * This works even if those additional words don't even appear in the training set.\n",
        "    * This allows you to build an accurate classifier mapping from sentences to emojis, even using a small training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yht0mqvw3afZ"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "- [Packages](#0)\n",
        "\n",
        "- [1 - Dataset EMOJISET](#1)\n",
        "- [2 - Emoji prediction Using LSTMs in Keras](#2)\n",
        "    - [2.1 - Model Overview](#2-1)\n",
        "    - [2.2 Keras and Mini-batching](#2-2)\n",
        "    - [2.3 - The Embedding Layer](#2-3)\n",
        "        - [- sentences_to_indices](#ex-3)\n",
        "        - [- pretrained_embedding_layer](#ex-4)\n",
        "    - [- Building the Model](#2-4)\n",
        "    - [2.5 - Train the Model](#2-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsztVBA8cFIg"
      },
      "source": [
        "<a name='0'></a>\n",
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lMZ9xg8MFHZU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from emo_utils import *\n",
        "import matplotlib.pyplot as plt\n",
        "import emoji\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av0PwZYscFIh"
      },
      "source": [
        "<a name='1'></a>\n",
        "### 1 - Dataset EMOJISET\n",
        "You have a tiny dataset (X, Y) where:\n",
        "- X contains 127 sentences (strings).\n",
        "- Y contains an integer label between 0 and 4 corresponding to an emoji for each sentence.\n",
        "\n",
        "<img src=\"images/data_set.png\" style=\"width:700px;height:300px;\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "OvuoZ8pWcFIi"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
        "X_test, Y_test = read_csv('data/tesss.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3dmH1tD3afh"
      },
      "source": [
        "In the below code cell, we will find out the sentence with the maximum number of words, and will store it's length in `maxLen` (*i.e., the number of words in the longest sentence, which will be used further*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DjAuDbxrcFIi"
      },
      "outputs": [],
      "source": [
        "maxLen = len(max(X_train, key=lambda x: len(x.split())).split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE1Zd2SMcFIj",
        "outputId": "1cd4af10-23ad-4bb9-be59-468fdc7e9a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "never talk to me again :disappointed:\n",
            "I am proud of your achievements :smile:\n",
            "It is the worst day in my life :disappointed:\n",
            "Miss you so much ‚ù§Ô∏è\n",
            "food is life üç¥\n",
            "I love you mum ‚ù§Ô∏è\n",
            "Stop saying bullshit :disappointed:\n",
            "congratulations on your acceptance :smile:\n",
            "The assignment is too long  :disappointed:\n",
            "I want to go play ‚öæ\n"
          ]
        }
      ],
      "source": [
        "for idx in range(10):\n",
        "    print(X_train[idx], label_to_emoji(Y_train[idx]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI8mJoafcFIp"
      },
      "source": [
        "<a name='1-3'></a>\n",
        "### - word_to_vec_map\n",
        "\n",
        "load the `word_to_vec_map`, which contains all the vector representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "QXI3avt7cFIq"
      },
      "outputs": [],
      "source": [
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB2ZN6ajcFIr",
        "outputId": "eb9eda62-8760-4419-b231-ffbb29e66ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the index of cucumber in the vocabulary is 113317\n",
            "the 289846th word in the vocabulary is potatos\n"
          ]
        }
      ],
      "source": [
        "word = \"cucumber\"\n",
        "idx = 289846\n",
        "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
        "print(\"the\", str(idx) + \"th word in the vocabulary is\", index_to_word[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEeTqpjlcFI2"
      },
      "source": [
        "<a name='2'></a>\n",
        "## 2 - Emojifier-V2: Using LSTMs in Keras\n",
        "\n",
        "We're going to build an LSTM model that takes word **sequences** as input! This model will be able to account for word ordering.\n",
        "\n",
        "Emojifier-V2 will use pre-trained word embeddings to represent words. We'll feed word embeddings into an LSTM, and the LSTM will learn to predict the most appropriate emoji."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7LJvriXcFI3"
      },
      "source": [
        "<a name='2-1'></a>\n",
        "### 2.1 - Model Overview\n",
        "\n",
        "Here is the model architecure that we will implement:\n",
        "\n",
        "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3W3WTbpcFI3"
      },
      "source": [
        "<a name='2-2'></a>\n",
        "### 2.2 Keras and Mini-batching\n",
        "\n",
        "We want to train Keras using mini-batches. However, most deep learning frameworks require that all sequences in the same mini-batch have the **same length**.\n",
        "\n",
        "This is what allows vectorization to work: If you had a 3-word sentence and a 4-word sentence, then the computations needed for them are different (one takes 3 steps of an LSTM, one takes 4 steps) so it's just not possible to do them both at the same time.\n",
        "    \n",
        "#### Padding Handles Sequences of Varying Length\n",
        "* The common solution to handling sequences of **different length** is to use padding.  Specifically:\n",
        "    * Set a maximum sequence length\n",
        "    * Pad all sequences to have the same length.\n",
        "    \n",
        "#### Example of Padding:\n",
        "* Given a maximum sequence length of 20, you could pad every sentence with \"0\"s so that each input sentence is of length 20.\n",
        "* Thus, the sentence \"I love you\" would be represented as $(e_{I}, e_{love}, e_{you}, \\vec{0}, \\vec{0}, \\ldots, \\vec{0})$.\n",
        "* In this example, any sentences longer than 20 words would have to be truncated.\n",
        "* One way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuwbNWS0cFI4"
      },
      "source": [
        "<a name='2-3'></a>\n",
        "### 2.3 - The Embedding Layer\n",
        "\n",
        "In Keras, the embedding matrix is represented as a \"layer.\"\n",
        "\n",
        "* The embedding matrix maps word indices to embedding vectors.\n",
        "    * The word indices are positive integers.\n",
        "    * The embedding vectors are dense vectors of fixed size.\n",
        "    * A \"dense\" vector is the opposite of a sparse vector. It means that most of its values are non-zero.  As a counter-example, a one-hot encoded vector is not \"dense.\"\n",
        "* The embedding matrix can be derived in two ways:\n",
        "    * Training a model to derive the embeddings from scratch.\n",
        "    * Using a pretrained embedding.\n",
        "    * Because our training set is quite small, we'll leave the GloVe embeddings fixed instead of updating them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhyVzuThcFI4"
      },
      "source": [
        "#### Inputs and Outputs to the Embedding Layer\n",
        "\n",
        "* The `Embedding()` layer's input is an integer matrix of size **(batch size, max input length)**.\n",
        "    * This input corresponds to sentences converted into lists of indices (integers).\n",
        "    * The largest integer (the highest word index) in the input should be no larger than the vocabulary size.\n",
        "* The embedding layer outputs an array of shape (batch size, max input length, dimension of word vectors).\n",
        "\n",
        "* The figure shows the propagation of two example sentences through the embedding layer.\n",
        "    * Both examples have been zero-padded to a length of `max_len=5`.\n",
        "    * The word embeddings are 50 units in length.\n",
        "    * The final dimension of the representation is  `(2,max_len,50)`.\n",
        "\n",
        "<img src=\"images/embedding1.png\" style=\"width:700px;height:250px;\">\n",
        "<caption><center><font color='purple'><b>Figure 4</b>: Embedding layer</center></caption>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnoTtNWBcFI5"
      },
      "source": [
        "#### Prepare the Input Sentences\n",
        "\n",
        "<a name='ex-3'></a>\n",
        "### Sentences_to_indices function\n",
        "\n",
        "This function processes an array of sentences X and returns inputs to the embedding layer:\n",
        "\n",
        "* Convert each training sentences into a list of indices (the indices correspond to each word in the sentence)\n",
        "* Zero-pad all these lists so that their length is the length of the longest sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Z0SixlIwcFI5"
      },
      "outputs": [],
      "source": [
        "def sentences_to_indices(X, word_to_index, max_len):\n",
        "    \"\"\"\n",
        "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
        "    The output shape should be such that it can be given to `Embedding()` (described in Figure 4).\n",
        "\n",
        "    Arguments:\n",
        "    X -- array of sentences (strings), of shape (m,)\n",
        "    word_to_index -- a dictionary containing the each word mapped to its index\n",
        "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this.\n",
        "\n",
        "    Returns:\n",
        "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
        "    \"\"\"\n",
        "\n",
        "    m = X.shape[0]                                   # number of training examples\n",
        "\n",
        "    # Initialize X_indices as a numpy matrix of zeros and the correct shape\n",
        "    X_indices = np.zeros((m,max_len))\n",
        "\n",
        "    for i in range(m):                               # loop over training examples\n",
        "\n",
        "        # Convert the ith training sentence in lower case and split is into words.\n",
        "        sentence_words = X[i].lower().split()\n",
        "\n",
        "        # Initialize j to 0\n",
        "        j = 0\n",
        "\n",
        "        # Loop over the words of sentence_words\n",
        "\n",
        "        for w in sentence_words:\n",
        "            # if w exists in the word_to_index dictionary\n",
        "            if w in word_to_index:\n",
        "                # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
        "                X_indices[i, j] = word_to_index[w]\n",
        "                # Increment j to j + 1\n",
        "                j = j + 1\n",
        "\n",
        "    return X_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reyHmseecFI6"
      },
      "source": [
        "check what `sentences_to_indices()` does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBL1PMOCcFI6",
        "outputId": "86966e1a-3b80-4b16-a635-25b785f18c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
            "X1_indices =\n",
            " [[155345. 225122.      0.      0.      0.]\n",
            " [220930. 286375.  69714.      0.      0.]\n",
            " [151204. 192973. 302254. 151349. 394475.]]\n"
          ]
        }
      ],
      "source": [
        "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
        "X1_indices = sentences_to_indices(X1, word_to_index, max_len=5)\n",
        "print(\"X1 =\", X1)\n",
        "print(\"X1_indices =\\n\", X1_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OJPAEM5cFI6"
      },
      "source": [
        "#### Build Embedding Layer\n",
        "\n",
        "* The embedding layer takes as input a list of word indices.\n",
        "    * `sentences_to_indices()` creates these word indices.\n",
        "* The embedding layer will return the word embeddings for a sentence.\n",
        "\n",
        "<a name='ex-4'></a>\n",
        "### - pretrained_embedding_layer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "XBlEpiVkcFI7"
      },
      "outputs": [],
      "source": [
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "    \"\"\"\n",
        "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
        "\n",
        "    Arguments:\n",
        "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
        "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
        "\n",
        "    Returns:\n",
        "    embedding_layer -- pretrained layer Keras instance\n",
        "    \"\"\"\n",
        "\n",
        "    vocab_size = len(word_to_index) + 1              # adding 1 to fit Keras embedding\n",
        "    any_word = list(word_to_vec_map.keys())[0]\n",
        "    emb_dim = word_to_vec_map[any_word].shape[0]    # define dimensionality of your GloVe word vectors (= 50)\n",
        "\n",
        "    # Step 1\n",
        "    # Initialize the embedding matrix as a numpy array of zeros.\n",
        "    # See instructions above to choose the correct shape.\n",
        "    emb_matrix = np.zeros((vocab_size, emb_dim))\n",
        "\n",
        "    # Step 2\n",
        "    # Set each row \"idx\" of the embedding matrix to be\n",
        "    # the word vector representation of the idx'th word of the vocabulary\n",
        "    for word, idx in word_to_index.items():\n",
        "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
        "\n",
        "    # Step 3\n",
        "    # Define Keras embedding layer with the correct input and output sizes\n",
        "    # Make it non-trainable.\n",
        "    embedding_layer = Embedding(vocab_size, emb_dim, trainable = False)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # Step 4\n",
        "    # Build the embedding layer, it is required before setting the weights of the embedding layer.\n",
        "    embedding_layer.build((None,))\n",
        "\n",
        "    # Set the weights of the embedding layer to the embedding matrix.\n",
        "    embedding_layer.set_weights([emb_matrix])\n",
        "\n",
        "    return embedding_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn4iGb0AcFI7",
        "outputId": "7785ed21-51c1-4abd-9461-cac1b205d28d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights[0][1][1] = 0.39031\n",
            "Input_dim 400001\n",
            "Output_dim 50\n"
          ]
        }
      ],
      "source": [
        "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "print(\"weights[0][1][1] =\", embedding_layer.get_weights()[0][1][1])\n",
        "print(\"Input_dim\", embedding_layer.input_dim)\n",
        "print(\"Output_dim\",embedding_layer.output_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEsWnZ_2cFI7"
      },
      "source": [
        "<a name='2-4'></a>\n",
        "### 2.4 - Building the Model\n",
        "\n",
        "Now We're ready to build the model, in which we feed the embedding layer's output to an LSTM network!\n",
        "\n",
        "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Pb2ugsSUcFI7"
      },
      "outputs": [],
      "source": [
        "def Emoji_Model(input_shape, word_to_vec_map, word_to_index):\n",
        "    \"\"\"\n",
        "    Function creating the Emojify-v2 model's graph.\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the input, usually (max_len,)\n",
        "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
        "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
        "\n",
        "    Returns:\n",
        "    model -- a model instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define sentence_indices as the input of the graph.\n",
        "    sentence_indices = Input(shape = input_shape, dtype = 'int32')\n",
        "\n",
        "    # Create the embedding layer pretrained with GloVe Vectors\n",
        "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "\n",
        "    # Propagate sentence_indices through your embedding layer\n",
        "    embeddings = embedding_layer(sentence_indices)\n",
        "\n",
        "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
        "    X = LSTM(128, return_sequences=True)(embeddings)\n",
        "    # Add dropout with a probability of 0.5\n",
        "    X = Dropout(rate = 0.5)(X)\n",
        "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
        "    X = LSTM(128, return_sequences=False)(X)\n",
        "    # Add dropout with a probability of 0.5\n",
        "    X = Dropout(rate = 0.5)(X)\n",
        "    # Propagate X through a Dense layer with 5 units\n",
        "    X = Dense(units = 5)(X)\n",
        "    # Add a softmax activation\n",
        "    X = Activation('softmax')(X)\n",
        "\n",
        "    # Create Model instance which converts sentence_indices into X.\n",
        "    model = Model(inputs=sentence_indices, outputs=X)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VamRAKtcFI8"
      },
      "source": [
        "\n",
        "* Because all sentences in the dataset are less than 10 words, `max_len = 10` was chosen.  \n",
        "* architecture uses 20,223,927 parameters, of which 20,000,050 (the word embeddings) are non-trainable, with the remaining 223,877 being trainable.\n",
        "* Because our vocabulary size has 400,001 words (with valid indices from 0 to 400,000) there are 400,001\\*50 = 20,000,050 non-trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fLhXJ9ucFI8",
        "outputId": "72528a4c-6317-487b-abd6-7743fc989a3b",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 10)]              0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 10, 50)            20000050  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 10, 128)           91648     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10, 128)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 645       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20223927 (77.15 MB)\n",
            "Trainable params: 223877 (874.52 KB)\n",
            "Non-trainable params: 20000050 (76.29 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Emoji_Model((maxLen,), word_to_vec_map, word_to_index)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKIsZqqicFI8"
      },
      "source": [
        "#### Compile the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "aMf79f45cFI9"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX6NORy7cFI9"
      },
      "source": [
        "<a name='2-5'></a>\n",
        "### 2.5 - Train the Model\n",
        "\n",
        "It's time to train our model, it takes as input an array of shape (`m`, `max_len`) and outputs probability vectors of shape (`m`, `number of classes`). Thus, we have to convert X_train (array of sentences as strings) to X_train_indices (array of sentences as list of word indices), and Y_train (labels as indices) to Y_train_oh (labels as one-hot vectors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "UgsBnWQqcFI-"
      },
      "outputs": [],
      "source": [
        "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
        "Y_train_oh = convert_to_one_hot(Y_train, C = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "LtFpvyJicFI_",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e40189-2e20-4ca5-e99e-2002b1fdaaff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 10s 9ms/step - loss: 1.5977 - accuracy: 0.2879\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.4896 - accuracy: 0.3258\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.4675 - accuracy: 0.3485\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.3890 - accuracy: 0.4621\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.2526 - accuracy: 0.5379\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.1251 - accuracy: 0.5909\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.9969 - accuracy: 0.6742\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.9661 - accuracy: 0.6439\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.8402 - accuracy: 0.7424\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.7494 - accuracy: 0.7273\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6904 - accuracy: 0.7803\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5621 - accuracy: 0.7803\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5773 - accuracy: 0.7955\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6271 - accuracy: 0.7500\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4943 - accuracy: 0.8030\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.8106\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8712\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3463 - accuracy: 0.8788\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2994 - accuracy: 0.8939\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3451 - accuracy: 0.9015\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3031 - accuracy: 0.9015\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3039 - accuracy: 0.9091\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2273 - accuracy: 0.9167\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2485 - accuracy: 0.9015\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1724 - accuracy: 0.9470\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1222 - accuracy: 0.9621\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1482 - accuracy: 0.9470\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0923 - accuracy: 0.9848\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1001 - accuracy: 0.9773\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1177 - accuracy: 0.9545\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.1440 - accuracy: 0.9394\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0985 - accuracy: 0.9621\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.9773\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1205 - accuracy: 0.9697\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2271 - accuracy: 0.9242\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.2678 - accuracy: 0.9167\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1652 - accuracy: 0.9470\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0671 - accuracy: 0.9773\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0755 - accuracy: 0.9773\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0498 - accuracy: 0.9924\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0488 - accuracy: 0.9773\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0285 - accuracy: 0.9924\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0268 - accuracy: 0.9924\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0121 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0142 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0406 - accuracy: 0.9924\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0515 - accuracy: 0.9848\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9924\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a8c669bd8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIbcdVibcFJA",
        "outputId": "093f4dd5-b204-4989-c54e-c5abc815fc71",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 11ms/step - loss: 0.6871 - accuracy: 0.8036\n",
            "\n",
            "Test accuracy =  0.8035714030265808\n"
          ]
        }
      ],
      "source": [
        "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
        "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
        "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
        "print()\n",
        "print(\"Test accuracy = \", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGg00oBRcFJD"
      },
      "source": [
        "try it on your own example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEgCsIE7cFJE",
        "outputId": "7934f010-1d63-46bf-d863-84e7eb0237b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "Sorry, I cannot play ‚öæ\n"
          ]
        }
      ],
      "source": [
        "# Change the sentence below to see your prediction. Make sure all the words are in the Glove embeddings.\n",
        "x_test = np.array(['Sorry, I cannot play'])\n",
        "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
        "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "zhyVzuThcFI4"
      ],
      "provenance": []
    },
    "coursera": {
      "schema_names": [
        "DLSC5W2-A2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}